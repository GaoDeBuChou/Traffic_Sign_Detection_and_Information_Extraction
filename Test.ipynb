{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Test.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyM0UlNXBtHEJ5EYAAURhz5P"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ip7u721l4vr"
   },
   "source": [
    "## Install OCR Tool"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0kGhZygpKL1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1608279774152,
     "user_tz": 300,
     "elapsed": 4965,
     "user": {
      "displayName": "Zhiyu Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiZTAPdoEeW3hG0uJsMY611QpakuVdT_pOJxvXk=s64",
      "userId": "12328658371610848538"
     }
    },
    "outputId": "13a4ad6c-d41c-462f-8a52-7de504402cf5"
   },
   "source": [
    "!sudo apt install tesseract-ocr\n",
    "!pip install pytesseract"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 57 not upgraded.\n",
      "Requirement already satisfied: pytesseract in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49OMIY7lrWt1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1608279774154,
     "user_tz": 300,
     "elapsed": 4963,
     "user": {
      "displayName": "Zhiyu Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiZTAPdoEeW3hG0uJsMY611QpakuVdT_pOJxvXk=s64",
      "userId": "12328658371610848538"
     }
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import pytesseract\n",
    "import re\n",
    "from google.colab.patches import cv2_imshow"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyqGT-Achv68"
   },
   "source": [
    "## Load YOLO Weights\n",
    "Put the path to your \".weights\" file at the first line"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bma3WQygrZzb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1608279774756,
     "user_tz": 300,
     "elapsed": 5563,
     "user": {
      "displayName": "Zhiyu Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiZTAPdoEeW3hG0uJsMY611QpakuVdT_pOJxvXk=s64",
      "userId": "12328658371610848538"
     }
    }
   },
   "source": [
    "weight_file_path = \"yolov3_training_last.weights\"\n",
    "net = cv2.dnn.readNet(weight_file_path, \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABV4bnu7h7-u"
   },
   "source": [
    "## Target Classes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iOlhkVGqtqJ9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1608279774757,
     "user_tz": 300,
     "elapsed": 5562,
     "user": {
      "displayName": "Zhiyu Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiZTAPdoEeW3hG0uJsMY611QpakuVdT_pOJxvXk=s64",
      "userId": "12328658371610848538"
     }
    }
   },
   "source": [
    "# Name custom object\n",
    "classes = [\"do not enter\", \"guide\", \"interstate highway\", \"us highway\", \"speed limit\", \"one way\",\n",
    "           \"no left turn\", \"stop\", \"no right turn\", \"no u turn\", \"railway crossing\", \"yield\"]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhFvNtLvikGs"
   },
   "source": [
    "## YOLO Object Detection\n",
    "Modified from [Sergio Canu - Train YOLO to detect a custom object (online with free GPU)](https://pysource.com/wp-content/uploads/2020/04/train_yolo_to_detect_custom_object.zip)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0ipHlwGyt12X",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1608279774757,
     "user_tz": 300,
     "elapsed": 5560,
     "user": {
      "displayName": "Zhiyu Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiZTAPdoEeW3hG0uJsMY611QpakuVdT_pOJxvXk=s64",
      "userId": "12328658371610848538"
     }
    }
   },
   "source": [
    "def yolo(img):\n",
    "    # Expected size in 600 * 800:\n",
    "    ratio = min(max(600 / img.shape[0], 800 / img.shape[1]), 1)\n",
    "    img = cv2.resize(img, None, fx=ratio, fy=ratio)\n",
    "    height, width, channels = img.shape\n",
    "    # Detecting objects:\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    # Getting classes and bounding boxes:\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.3:  # object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    # Non-maximum suppression:\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    results = [(class_ids[i], boxes[i]) for i in range(len(boxes)) if i in indexes]\n",
    "    # Showing results:\n",
    "    img_toshow = img.copy()\n",
    "    for class_id, box in results:\n",
    "        x, y, w, h = box\n",
    "        color = colors[class_id]\n",
    "        cv2.rectangle(img_toshow, (x, y), (x + w, y + h), color, 2)\n",
    "    cv2_imshow(img_toshow)\n",
    "    return img, results"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHimZpvCmi38"
   },
   "source": [
    "## Optical Character Recognition\n",
    "Credit to [Hucker Marius - Optical Character Recognition (OCR) with less than 10 Lines of Code using Python](https://towardsdatascience.com/optical-character-recognition-ocr-with-less-than-12-lines-of-code-using-python-48404218cccb)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DVEjodU_uGvs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1608279774758,
     "user_tz": 300,
     "elapsed": 5559,
     "user": {
      "displayName": "Zhiyu Lei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiZTAPdoEeW3hG0uJsMY611QpakuVdT_pOJxvXk=s64",
      "userId": "12328658371610848538"
     }
    }
   },
   "source": [
    "def ocr(img, yolo_results):\n",
    "    for class_id, box in yolo_results:\n",
    "        x, y, w, h = box\n",
    "        crop = img[y:y+h, x:x+w, :]\n",
    "        crop = cv2.resize(crop, None, fx=2, fy=2)\n",
    "        cv2_imshow(crop)\n",
    "        # Alternatively: can be skipped if you have a Blackwhite image\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_RGB2GRAY)\n",
    "        gray, img_bin = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        gray = cv2.bitwise_not(img_bin)\n",
    "        # Removing noise by morphological operations:\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        crop = cv2.erode(gray, kernel, iterations=1)\n",
    "        crop = cv2.dilate(crop, kernel, iterations=1)\n",
    "        cv2_imshow(crop)\n",
    "        # Recognizing characters:\n",
    "        output = pytesseract.image_to_string(crop)\n",
    "        # Optimizing output:\n",
    "        lines = re.split(\"\\n+\", output)\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            words = re.split(\"\\\\s+\", line.strip().upper())\n",
    "            new_line = \" \".join(words)\n",
    "            if new_line not in (\"\", \"W\", \"WO\", \"OW\"):\n",
    "                new_lines.append(new_line)\n",
    "        new_output = \"\\n\".join(new_lines)\n",
    "        print(\"OUTPUT:\\n\")\n",
    "        print(new_output)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUhoD34_njUh"
   },
   "source": [
    "## Test the Model on Images\n",
    "Put the path to your image file at the first line"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lSOt3MEKvw-d"
   },
   "source": [
    "image_path = \"Test1.jpg\"\n",
    "img = cv2.imread(image_path)\n",
    "img, yolo_results = yolo(img)\n",
    "ocr(img, yolo_results)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}